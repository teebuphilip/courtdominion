#!/usr/bin/env python3
"""
Generate usage rate and minutes distribution profiles from 30 years of NBA game logs.

Combines Feature 4 (Usage Rate Patterns) and Feature 5 (Minutes Distribution)
into a single output file since they share the same (age, position, role) keys.

Produces:
    static_data/usage/usage_profiles.py

Usage:
    python -m data_collection.generate_usage_profiles
"""

from pathlib import Path
from typing import Dict, Tuple

import numpy as np
import pandas as pd

from data_collection.utils import (
    STATIC_DATA_DIR,
    load_all_seasons,
    rebucket_role,
)

MIN_SAMPLE_SIZE = 50


def compute_season_roles(df: pd.DataFrame) -> pd.DataFrame:
    """
    Compute season-average minutes per player-season, then re-bucket role.

    Groups by (player_id, season_start_year), computes mean minutes_played,
    applies rebucket_role() to get the season role, and merges it back onto
    every game row.
    """
    season_avg = (
        df.groupby(["player_id", "season_start_year"])["minutes_played"]
        .mean()
        .reset_index()
        .rename(columns={"minutes_played": "season_avg_minutes"})
    )
    season_avg["rebucketed_role"] = season_avg["season_avg_minutes"].apply(rebucket_role)

    return df.merge(
        season_avg[["player_id", "season_start_year", "rebucketed_role"]],
        on=["player_id", "season_start_year"],
        how="left",
    )


def classify_volatility(stddev: float) -> str:
    """Classify minutes volatility from standard deviation."""
    if stddev < 5:
        return "low"
    if stddev <= 10:
        return "medium"
    return "high"


def build_usage_profiles(
    df: pd.DataFrame,
    min_sample: int = MIN_SAMPLE_SIZE,
) -> Dict[Tuple[int, str, str], dict]:
    """
    Group by (age, position_group, rebucketed_role) and compute usage + minutes stats.

    F4: usage_rate = (FGA + 0.44*FTA + TOV) / minutes_played
        fga_per_minute = FGA / minutes_played
    F5: minutes percentiles (10th/50th/90th) + volatility classification
    """
    grouped = df.groupby(["age", "position_group", "rebucketed_role"])

    profiles = {}
    for (age, pos, role), group in grouped:
        if len(group) < min_sample:
            continue

        entry = {"sample_size": len(group)}

        # F4: Usage rate stats
        usage = group["usage_rate"]
        entry["avg_usage_rate"] = round(float(usage.mean()), 4)
        entry["stddev_usage_rate"] = round(float(usage.std(ddof=1)), 4)

        fga_pm = group["fga_per_minute"]
        entry["avg_fga_per_minute"] = round(float(fga_pm.mean()), 4)
        entry["stddev_fga_per_minute"] = round(float(fga_pm.std(ddof=1)), 4)

        # F5: Minutes distribution
        mins = group["minutes_played"]
        entry["minutes_10th"] = round(float(mins.quantile(0.10)), 4)
        entry["minutes_50th"] = round(float(mins.quantile(0.50)), 4)
        entry["minutes_90th"] = round(float(mins.quantile(0.90)), 4)

        mins_std = float(mins.std(ddof=1))
        entry["minutes_volatility"] = classify_volatility(mins_std)

        profiles[(int(age), pos, role)] = entry

    return profiles


# Field order for deterministic output
USAGE_FIELDS = [
    "avg_usage_rate",
    "stddev_usage_rate",
    "avg_fga_per_minute",
    "stddev_fga_per_minute",
    "minutes_10th",
    "minutes_50th",
    "minutes_90th",
]


def write_profiles_file(
    profiles: dict,
    variable_name: str,
    output_path: Path,
) -> None:
    """Write profiles dict as a Python literal to a .py file."""
    lines = []
    lines.append("# auto-generated by generate_usage_profiles.py")
    lines.append("# Do not edit manually â€” re-run the generator to update.")
    lines.append("")
    lines.append(f"{variable_name} = {{")

    for key in sorted(profiles.keys()):
        entry = profiles[key]
        age, pos, role = key
        lines.append(f"    ({age}, '{pos}', '{role}'): {{")

        for field in USAGE_FIELDS:
            lines.append(f"        '{field}': {entry[field]},")

        lines.append(f"        'minutes_volatility': '{entry['minutes_volatility']}',")
        lines.append(f"        'sample_size': {entry['sample_size']},")
        lines.append("    },")

    lines.append("}")
    lines.append("")

    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text("\n".join(lines))


def main() -> None:
    """Generate usage + minutes distribution profiles."""
    print("Loading all seasons...")
    df = load_all_seasons()
    print(f"  Loaded {len(df):,} rows")

    # Drop rows where age is null
    before = len(df)
    df = df.dropna(subset=["age"])
    df["age"] = df["age"].astype(int)
    print(f"  Dropped {before - len(df):,} rows with null age ({len(df):,} remaining)")

    # Drop rows where position_group is None
    before = len(df)
    df = df.dropna(subset=["position_group"])
    print(
        f"  Dropped {before - len(df):,} rows with unknown position "
        f"({len(df):,} remaining)"
    )

    # Filter out zero/negative minutes (avoid division by zero)
    before = len(df)
    df = df[df["minutes_played"] > 0]
    print(
        f"  Dropped {before - len(df):,} rows with 0 minutes "
        f"({len(df):,} remaining)"
    )

    # Compute season-average roles (re-bucketing)
    print("Computing season-average roles...")
    df = compute_season_roles(df)

    # Compute derived columns for F4
    df["usage_rate"] = (df["fga"] + 0.44 * df["fta"] + df["turnovers"]) / df["minutes_played"]
    df["fga_per_minute"] = df["fga"] / df["minutes_played"]

    # Build profiles
    print("Building usage + minutes profiles...")
    profiles = build_usage_profiles(df)
    print(f"  Buckets: {len(profiles)} (after min sample filter)")

    # Write output
    output_path = STATIC_DATA_DIR / "usage" / "usage_profiles.py"
    write_profiles_file(profiles, "USAGE_PROFILES", output_path)
    print(f"  Written: {output_path}")

    print("\nDone.")


if __name__ == "__main__":
    main()
