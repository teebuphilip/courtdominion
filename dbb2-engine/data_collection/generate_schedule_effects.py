#!/usr/bin/env python3
"""
Generate B2B decline and rest days boost profiles from 30 years of NBA game logs.

Feature 6: Back-to-back performance decline (2nd night vs normal)
Feature 9: Extended rest boost (3+ days rest vs normal)

Produces:
    static_data/calendars/schedule_effects.py

Usage:
    python -m data_collection.generate_schedule_effects
"""

from pathlib import Path
from typing import Dict, Tuple

import pandas as pd

from data_collection.utils import (
    STATIC_DATA_DIR,
    age_bucket,
    load_all_seasons,
    rebucket_role,
)

MIN_SAMPLE_SIZE = 50


def compute_season_roles(df: pd.DataFrame) -> pd.DataFrame:
    """Compute season-average minutes per player-season, then re-bucket role."""
    season_avg = (
        df.groupby(["player_id", "season_start_year"])["minutes_played"]
        .mean()
        .reset_index()
        .rename(columns={"minutes_played": "season_avg_minutes"})
    )
    season_avg["rebucketed_role"] = season_avg["season_avg_minutes"].apply(rebucket_role)

    return df.merge(
        season_avg[["player_id", "season_start_year", "rebucketed_role"]],
        on=["player_id", "season_start_year"],
        how="left",
    )


def compute_days_since_last_game(df: pd.DataFrame) -> pd.DataFrame:
    """
    Sort by (player_id, game_date) and compute days between consecutive games.

    Adds 'days_since_last' column (NaN for first game of each player-season).
    """
    df = df.sort_values(["player_id", "game_date"]).reset_index(drop=True)
    df["days_since_last"] = (
        df.groupby("player_id")["game_date"]
        .diff()
        .dt.days
    )
    return df


def build_schedule_effects(
    df: pd.DataFrame,
    min_sample: int = MIN_SAMPLE_SIZE,
) -> Dict[Tuple[str, str, str], dict]:
    """
    Build B2B decline + rest boost multipliers by (age_bucket, position, role).

    B2B game 2: days_since_last == 1
    Normal baseline: days_since_last == 2
    Extended rest: days_since_last >= 3
    """
    b2b = df[df["days_since_last"] == 1]
    normal = df[df["days_since_last"] == 2]
    rest = df[df["days_since_last"] >= 3]

    group_cols = ["age_bucket", "position_group", "rebucketed_role"]

    # Compute group averages for each subset
    normal_avg = normal.groupby(group_cols)[["minutes_played", "points"]].mean()
    b2b_avg = b2b.groupby(group_cols)[["minutes_played", "points"]].mean()
    rest_avg = rest.groupby(group_cols)[["minutes_played", "points"]].mean()

    b2b_counts = b2b.groupby(group_cols).size()
    rest_counts = rest.groupby(group_cols).size()

    profiles = {}
    for idx in normal_avg.index:
        bucket, pos, role = idx

        b2b_n = int(b2b_counts.get(idx, 0))
        rest_n = int(rest_counts.get(idx, 0))

        # Need baseline + at least one of B2B or rest to pass threshold
        if b2b_n < min_sample and rest_n < min_sample:
            continue

        norm_mins = normal_avg.loc[idx, "minutes_played"]
        norm_pts = normal_avg.loc[idx, "points"]

        # Avoid division by zero
        if norm_mins <= 0 or norm_pts <= 0:
            continue

        entry = {}

        # F6: B2B decline
        if b2b_n >= min_sample and idx in b2b_avg.index:
            entry["b2b_minutes_dropoff"] = round(
                float(b2b_avg.loc[idx, "minutes_played"] / norm_mins), 4
            )
            entry["b2b_scoring_dropoff"] = round(
                float(b2b_avg.loc[idx, "points"] / norm_pts), 4
            )
            entry["b2b_sample_size"] = b2b_n
        else:
            entry["b2b_minutes_dropoff"] = None
            entry["b2b_scoring_dropoff"] = None
            entry["b2b_sample_size"] = b2b_n

        # F9: Rest boost
        if rest_n >= min_sample and idx in rest_avg.index:
            entry["rest_minutes_boost"] = round(
                float(rest_avg.loc[idx, "minutes_played"] / norm_mins), 4
            )
            entry["rest_scoring_boost"] = round(
                float(rest_avg.loc[idx, "points"] / norm_pts), 4
            )
            entry["rest_sample_size"] = rest_n
        else:
            entry["rest_minutes_boost"] = None
            entry["rest_scoring_boost"] = None
            entry["rest_sample_size"] = rest_n

        profiles[(bucket, pos, role)] = entry

    return profiles


EFFECT_FIELDS = [
    "b2b_minutes_dropoff",
    "b2b_scoring_dropoff",
    "b2b_sample_size",
    "rest_minutes_boost",
    "rest_scoring_boost",
    "rest_sample_size",
]


def write_effects_file(
    profiles: dict,
    variable_name: str,
    output_path: Path,
) -> None:
    """Write schedule effects dict as a Python literal to a .py file."""
    lines = []
    lines.append("# auto-generated by generate_schedule_effects.py")
    lines.append("# Do not edit manually â€” re-run the generator to update.")
    lines.append("")
    lines.append(f"{variable_name} = {{")

    for key in sorted(profiles.keys()):
        entry = profiles[key]
        bucket, pos, role = key
        lines.append(f"    ('{bucket}', '{pos}', '{role}'): {{")

        for field in EFFECT_FIELDS:
            val = entry[field]
            if val is None:
                lines.append(f"        '{field}': None,")
            elif isinstance(val, int):
                lines.append(f"        '{field}': {val},")
            else:
                lines.append(f"        '{field}': {val},")

        lines.append("    },")

    lines.append("}")
    lines.append("")

    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text("\n".join(lines))


def main() -> None:
    """Generate B2B decline + rest boost schedule effects."""
    print("Loading all seasons...")
    df = load_all_seasons()
    print(f"  Loaded {len(df):,} rows")

    # Clean data
    before = len(df)
    df = df.dropna(subset=["age"])
    df["age"] = df["age"].astype(int)
    print(f"  Dropped {before - len(df):,} rows with null age ({len(df):,} remaining)")

    before = len(df)
    df = df.dropna(subset=["position_group"])
    print(
        f"  Dropped {before - len(df):,} rows with unknown position "
        f"({len(df):,} remaining)"
    )

    before = len(df)
    df = df[df["minutes_played"] > 0]
    print(
        f"  Dropped {before - len(df):,} rows with 0 minutes "
        f"({len(df):,} remaining)"
    )

    # Compute season-average roles
    print("Computing season-average roles...")
    df = compute_season_roles(df)

    # Add age bucket
    df["age_bucket"] = df["age"].apply(age_bucket)
    before = len(df)
    df = df.dropna(subset=["age_bucket"])
    print(f"  Dropped {before - len(df):,} rows with null age bucket")

    # Compute days between games
    print("Computing days since last game...")
    df = compute_days_since_last_game(df)

    # Count game types
    b2b_count = (df["days_since_last"] == 1).sum()
    normal_count = (df["days_since_last"] == 2).sum()
    rest_count = (df["days_since_last"] >= 3).sum()
    print(f"  B2B game 2s: {b2b_count:,}")
    print(f"  Normal (2-day rest): {normal_count:,}")
    print(f"  Extended rest (3+ days): {rest_count:,}")

    # Build schedule effects
    print("Building schedule effects...")
    profiles = build_schedule_effects(df)
    print(f"  Buckets: {len(profiles)} (after min sample filter)")

    # Write output
    output_path = STATIC_DATA_DIR / "calendars" / "schedule_effects.py"
    write_effects_file(profiles, "SCHEDULE_EFFECTS", output_path)
    print(f"  Written: {output_path}")

    print("\nDone.")


if __name__ == "__main__":
    main()
