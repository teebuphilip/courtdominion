#!/usr/bin/env python3
"""
Generate age-based performance profile dictionaries from 30 years of NBA game logs.

Produces three output files:
    static_data/profiles/age_profiles_overall.py    (1995-2025)
    static_data/profiles/age_profiles_pre_modern.py (1995-2017)
    static_data/profiles/age_profiles_modern.py     (2017-2025)

Usage:
    python -m data_collection.generate_age_profiles
"""

from pathlib import Path
from typing import Dict, Tuple

import pandas as pd

from data_collection.utils import (
    STAT_COLUMNS,
    STATIC_DATA_DIR,
    load_all_seasons,
    rebucket_role,
)

MIN_SAMPLE_SIZE = 50

ERA_CONFIGS = [
    {
        "label": "overall",
        "start_year": 1995,
        "end_year": 2024,
        "variable_name": "AGE_PROFILES_OVERALL",
        "filename": "age_profiles_overall.py",
    },
    {
        "label": "pre_modern",
        "start_year": 1995,
        "end_year": 2017,
        "variable_name": "AGE_PROFILES_PRE_MODERN",
        "filename": "age_profiles_pre_modern.py",
    },
    {
        "label": "modern",
        "start_year": 2017,
        "end_year": 2024,
        "variable_name": "AGE_PROFILES_MODERN",
        "filename": "age_profiles_modern.py",
    },
]


def compute_season_roles(df: pd.DataFrame) -> pd.DataFrame:
    """
    Compute season-average minutes per player-season, then re-bucket role.

    Groups by (player_id, season_start_year), computes mean minutes_played,
    applies rebucket_role() to get the season role, and merges it back onto
    every game row.

    Returns:
        DataFrame with a new 'rebucketed_role' column.
    """
    season_avg = (
        df.groupby(["player_id", "season_start_year"])["minutes_played"]
        .mean()
        .reset_index()
        .rename(columns={"minutes_played": "season_avg_minutes"})
    )
    season_avg["rebucketed_role"] = season_avg["season_avg_minutes"].apply(rebucket_role)

    return df.merge(
        season_avg[["player_id", "season_start_year", "rebucketed_role"]],
        on=["player_id", "season_start_year"],
        how="left",
    )


def build_profiles(
    df: pd.DataFrame,
    min_sample: int = MIN_SAMPLE_SIZE,
) -> Dict[Tuple[int, str, str], dict]:
    """
    Group by (age, position_group, rebucketed_role) and compute stats.

    For each group with sufficient sample size, computes avg/stddev/variance
    for all 13 STAT_COLUMNS.

    Returns:
        Dict mapping (age, position_group, role) tuples to stat dicts.
    """
    grouped = df.groupby(["age", "position_group", "rebucketed_role"])

    profiles = {}
    for (age, pos, role), group in grouped:
        if len(group) < min_sample:
            continue

        entry = {"sample_size": len(group)}

        for stat in STAT_COLUMNS:
            col = group[stat]
            entry[f"avg_{stat}"] = round(float(col.mean()), 4)
            entry[f"stddev_{stat}"] = round(float(col.std(ddof=1)), 4)
            entry[f"variance_{stat}"] = round(float(col.var(ddof=1)), 4)

        profiles[(int(age), pos, role)] = entry

    return profiles


def write_profiles_file(
    profiles: dict,
    variable_name: str,
    output_path: Path,
) -> None:
    """
    Write profiles dict as a Python literal to a .py file.

    Output is sorted by (age, position, role) for deterministic diffs.
    """
    lines = []
    lines.append("# auto-generated by generate_age_profiles.py")
    lines.append("# Do not edit manually â€” re-run the generator to update.")
    lines.append("")
    lines.append(f"{variable_name} = {{")

    for key in sorted(profiles.keys()):
        entry = profiles[key]
        age, pos, role = key
        lines.append(f"    ({age}, '{pos}', '{role}'): {{")

        for stat in STAT_COLUMNS:
            lines.append(f"        'avg_{stat}': {entry[f'avg_{stat}']},")
            lines.append(f"        'stddev_{stat}': {entry[f'stddev_{stat}']},")
            lines.append(f"        'variance_{stat}': {entry[f'variance_{stat}']},")

        lines.append(f"        'sample_size': {entry['sample_size']},")
        lines.append("    },")

    lines.append("}")
    lines.append("")

    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text("\n".join(lines))


def main() -> None:
    """Generate all three era profile files."""
    print("Loading all seasons...")
    df = load_all_seasons()
    print(f"  Loaded {len(df):,} rows")

    # Drop rows where age is null
    before = len(df)
    df = df.dropna(subset=["age"])
    df["age"] = df["age"].astype(int)
    print(f"  Dropped {before - len(df):,} rows with null age ({len(df):,} remaining)")

    # Drop rows where position_group is None
    before = len(df)
    df = df.dropna(subset=["position_group"])
    print(
        f"  Dropped {before - len(df):,} rows with unknown position "
        f"({len(df):,} remaining)"
    )

    # Compute season-average roles (re-bucketing)
    print("Computing season-average roles...")
    df = compute_season_roles(df)

    # Generate profiles for each era
    output_dir = STATIC_DATA_DIR / "profiles"

    for config in ERA_CONFIGS:
        era_df = df[
            (df["season_start_year"] >= config["start_year"])
            & (df["season_start_year"] <= config["end_year"])
        ]

        print(f"\nGenerating {config['label']} profiles...")
        print(f"  Era: {config['start_year']}-{config['end_year']}")
        print(f"  Rows: {len(era_df):,}")

        profiles = build_profiles(era_df)
        print(f"  Buckets: {len(profiles)} (after min sample filter)")

        output_path = output_dir / config["filename"]
        write_profiles_file(profiles, config["variable_name"], output_path)
        print(f"  Written: {output_path}")

    print("\nDone.")


if __name__ == "__main__":
    main()
